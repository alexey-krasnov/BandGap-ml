{
 "cells": [
  {
   "cell_type": "code",
   "id": "eed2a328-700e-4d50-829e-cbac7c608502",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T15:56:59.789957Z",
     "start_time": "2025-03-13T15:56:59.194851Z"
    }
   },
   "source": [
    "from band_gap_ml.band_gap_predictor import predict_eg_from_file, predict_eg_from_formula\n",
    "from band_gap_ml.model_training import train_and_save_models"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 1. Train models",
   "id": "ff80a06614c933b5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 1.1 RandomForest",
   "id": "41645d09f2e65dff"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T14:27:34.013386Z",
     "start_time": "2025-03-13T14:19:52.960613Z"
    }
   },
   "cell_type": "code",
   "source": "train_and_save_models(model_type='RandomForest', use_grid_search=True)",
   "id": "f52435c184fb8e37",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting model training for RandomForest\n",
      "Model directory created: /Users/alekseikrasov/Desktop/OntoChem/work/ml_projects/BandGap-ml/band_gap_ml/models/randomforest\n",
      "1. Start training of classifier ...\n",
      "Importing RandomForestClassifier from sklearn.ensemble\n",
      "Starting grid search for classification...\n",
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "Best score: 0.9102182087419293\n",
      "Best parameters: {'max_depth': 40, 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 200}\n",
      "RandomForest Classification Best Parameters: {'max_depth': 40, 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 200}\n",
      "\n",
      "Accuracy: 0.9065040650406504\n",
      "Precision: 0.8921568627450981\n",
      "Recall: 0.9247967479674797\n",
      "F1_score: 0.908183632734531\n",
      "\n",
      "4. Start training regressor...\n",
      "Importing RandomForestRegressor from sklearn.ensemble\n",
      "Starting grid search for regression...\n",
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[2]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m \u001B[43mtrain_and_save_models\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_type\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mRandomForest\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43muse_grid_search\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/OntoChem/work/ml_projects/BandGap-ml/band_gap_ml/model_training.py:55\u001B[39m, in \u001B[36mtrain_and_save_models\u001B[39m\u001B[34m(classification_data_path, regression_data_path, model_type, classification_params, regression_params, use_grid_search)\u001B[39m\n\u001B[32m     51\u001B[39m regression_params = regression_params \u001B[38;5;129;01mor\u001B[39;00m Config.DEFAULT_GRID_PARAMS.get(model_type, {}).get(\u001B[33m'\u001B[39m\u001B[33mregression\u001B[39m\u001B[33m'\u001B[39m)\n\u001B[32m     52\u001B[39m \u001B[38;5;66;03m# Regression step\u001B[39;00m\n\u001B[32m     53\u001B[39m regression_results = train_regression_model(\n\u001B[32m     54\u001B[39m     regression_data_path, model_type, use_grid_search, regression_params\n\u001B[32m---> \u001B[39m\u001B[32m55\u001B[39m )\n\u001B[32m     57\u001B[39m models_statistics = {\n\u001B[32m     58\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33mmodel_type\u001B[39m\u001B[33m\"\u001B[39m: model_type,\n\u001B[32m     59\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33muse_grid_search\u001B[39m\u001B[33m\"\u001B[39m: use_grid_search,\n\u001B[32m   (...)\u001B[39m\u001B[32m     67\u001B[39m     }\n\u001B[32m     68\u001B[39m }\n\u001B[32m     70\u001B[39m \u001B[38;5;66;03m# Save models and scalers\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/OntoChem/work/ml_projects/BandGap-ml/band_gap_ml/model_training.py:142\u001B[39m, in \u001B[36mtrain_regression_model\u001B[39m\u001B[34m(data_path, model_type, use_grid_search, params)\u001B[39m\n\u001B[32m    140\u001B[39m     best_regressor, best_params = perform_grid_search(RegressorModel, X_train_scaled, Y_train, params, \u001B[33m'\u001B[39m\u001B[33mregression\u001B[39m\u001B[33m'\u001B[39m)\n\u001B[32m    141\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m142\u001B[39m     best_regressor = RegressorModel()\n\u001B[32m    143\u001B[39m     best_regressor.fit(X_train_scaled, Y_train)\n\u001B[32m    144\u001B[39m     best_params = \u001B[33m\"\u001B[39m\u001B[33mDefault parameters\u001B[39m\u001B[33m\"\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/OntoChem/work/ml_projects/BandGap-ml/band_gap_ml/model_training.py:172\u001B[39m, in \u001B[36mperform_grid_search\u001B[39m\u001B[34m(Model, X, y, params, task)\u001B[39m\n\u001B[32m    170\u001B[39m grid_search.fit(X, y)\n\u001B[32m    171\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mBest score: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mgrid_search.best_score_\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m)\n\u001B[32m--> \u001B[39m\u001B[32m172\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mBest parameters: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mgrid_search.best_params_\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m)\n\u001B[32m    173\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m grid_search.best_estimator_, grid_search.best_params_\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniforge3/envs/works_3.12/lib/python3.12/site-packages/sklearn/base.py:1389\u001B[39m, in \u001B[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001B[39m\u001B[34m(estimator, *args, **kwargs)\u001B[39m\n\u001B[32m   1382\u001B[39m     estimator._validate_params()\n\u001B[32m   1384\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[32m   1385\u001B[39m     skip_parameter_validation=(\n\u001B[32m   1386\u001B[39m         prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[32m   1387\u001B[39m     )\n\u001B[32m   1388\u001B[39m ):\n\u001B[32m-> \u001B[39m\u001B[32m1389\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfit_method\u001B[49m\u001B[43m(\u001B[49m\u001B[43mestimator\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniforge3/envs/works_3.12/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1024\u001B[39m, in \u001B[36mBaseSearchCV.fit\u001B[39m\u001B[34m(self, X, y, **params)\u001B[39m\n\u001B[32m   1018\u001B[39m     results = \u001B[38;5;28mself\u001B[39m._format_results(\n\u001B[32m   1019\u001B[39m         all_candidate_params, n_splits, all_out, all_more_results\n\u001B[32m   1020\u001B[39m     )\n\u001B[32m   1022\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m results\n\u001B[32m-> \u001B[39m\u001B[32m1024\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_run_search\u001B[49m\u001B[43m(\u001B[49m\u001B[43mevaluate_candidates\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1026\u001B[39m \u001B[38;5;66;03m# multimetric is determined here because in the case of a callable\u001B[39;00m\n\u001B[32m   1027\u001B[39m \u001B[38;5;66;03m# self.scoring the return type is only known after calling\u001B[39;00m\n\u001B[32m   1028\u001B[39m first_test_score = all_out[\u001B[32m0\u001B[39m][\u001B[33m\"\u001B[39m\u001B[33mtest_scores\u001B[39m\u001B[33m\"\u001B[39m]\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniforge3/envs/works_3.12/lib/python3.12/site-packages/sklearn/model_selection/_search.py:1571\u001B[39m, in \u001B[36mGridSearchCV._run_search\u001B[39m\u001B[34m(self, evaluate_candidates)\u001B[39m\n\u001B[32m   1569\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m_run_search\u001B[39m(\u001B[38;5;28mself\u001B[39m, evaluate_candidates):\n\u001B[32m   1570\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"Search all candidates in param_grid\"\"\"\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m1571\u001B[39m     \u001B[43mevaluate_candidates\u001B[49m\u001B[43m(\u001B[49m\u001B[43mParameterGrid\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mparam_grid\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniforge3/envs/works_3.12/lib/python3.12/site-packages/sklearn/model_selection/_search.py:970\u001B[39m, in \u001B[36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001B[39m\u001B[34m(candidate_params, cv, more_results)\u001B[39m\n\u001B[32m    962\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.verbose > \u001B[32m0\u001B[39m:\n\u001B[32m    963\u001B[39m     \u001B[38;5;28mprint\u001B[39m(\n\u001B[32m    964\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mFitting \u001B[39m\u001B[38;5;132;01m{0}\u001B[39;00m\u001B[33m folds for each of \u001B[39m\u001B[38;5;132;01m{1}\u001B[39;00m\u001B[33m candidates,\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    965\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33m totalling \u001B[39m\u001B[38;5;132;01m{2}\u001B[39;00m\u001B[33m fits\u001B[39m\u001B[33m\"\u001B[39m.format(\n\u001B[32m    966\u001B[39m             n_splits, n_candidates, n_candidates * n_splits\n\u001B[32m    967\u001B[39m         )\n\u001B[32m    968\u001B[39m     )\n\u001B[32m--> \u001B[39m\u001B[32m970\u001B[39m out = \u001B[43mparallel\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    971\u001B[39m \u001B[43m    \u001B[49m\u001B[43mdelayed\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_fit_and_score\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    972\u001B[39m \u001B[43m        \u001B[49m\u001B[43mclone\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbase_estimator\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    973\u001B[39m \u001B[43m        \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    974\u001B[39m \u001B[43m        \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    975\u001B[39m \u001B[43m        \u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    976\u001B[39m \u001B[43m        \u001B[49m\u001B[43mtest\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtest\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    977\u001B[39m \u001B[43m        \u001B[49m\u001B[43mparameters\u001B[49m\u001B[43m=\u001B[49m\u001B[43mparameters\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    978\u001B[39m \u001B[43m        \u001B[49m\u001B[43msplit_progress\u001B[49m\u001B[43m=\u001B[49m\u001B[43m(\u001B[49m\u001B[43msplit_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_splits\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    979\u001B[39m \u001B[43m        \u001B[49m\u001B[43mcandidate_progress\u001B[49m\u001B[43m=\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcand_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_candidates\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    980\u001B[39m \u001B[43m        \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mfit_and_score_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    981\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    982\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mcand_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparameters\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43msplit_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mproduct\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    983\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43menumerate\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcandidate_params\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    984\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43menumerate\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcv\u001B[49m\u001B[43m.\u001B[49m\u001B[43msplit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mrouted_params\u001B[49m\u001B[43m.\u001B[49m\u001B[43msplitter\u001B[49m\u001B[43m.\u001B[49m\u001B[43msplit\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    985\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    986\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    988\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(out) < \u001B[32m1\u001B[39m:\n\u001B[32m    989\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[32m    990\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mNo fits were performed. \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    991\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mWas the CV iterator empty? \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    992\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mWere there no candidates?\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    993\u001B[39m     )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniforge3/envs/works_3.12/lib/python3.12/site-packages/sklearn/utils/parallel.py:77\u001B[39m, in \u001B[36mParallel.__call__\u001B[39m\u001B[34m(self, iterable)\u001B[39m\n\u001B[32m     72\u001B[39m config = get_config()\n\u001B[32m     73\u001B[39m iterable_with_config = (\n\u001B[32m     74\u001B[39m     (_with_config(delayed_func, config), args, kwargs)\n\u001B[32m     75\u001B[39m     \u001B[38;5;28;01mfor\u001B[39;00m delayed_func, args, kwargs \u001B[38;5;129;01min\u001B[39;00m iterable\n\u001B[32m     76\u001B[39m )\n\u001B[32m---> \u001B[39m\u001B[32m77\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[34;43m__call__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43miterable_with_config\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniforge3/envs/works_3.12/lib/python3.12/site-packages/joblib/parallel.py:2007\u001B[39m, in \u001B[36mParallel.__call__\u001B[39m\u001B[34m(self, iterable)\u001B[39m\n\u001B[32m   2001\u001B[39m \u001B[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001B[39;00m\n\u001B[32m   2002\u001B[39m \u001B[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001B[39;00m\n\u001B[32m   2003\u001B[39m \u001B[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001B[39;00m\n\u001B[32m   2004\u001B[39m \u001B[38;5;66;03m# dispatch of the tasks to the workers.\u001B[39;00m\n\u001B[32m   2005\u001B[39m \u001B[38;5;28mnext\u001B[39m(output)\n\u001B[32m-> \u001B[39m\u001B[32m2007\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m output \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.return_generator \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43moutput\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniforge3/envs/works_3.12/lib/python3.12/site-packages/joblib/parallel.py:1650\u001B[39m, in \u001B[36mParallel._get_outputs\u001B[39m\u001B[34m(self, iterator, pre_dispatch)\u001B[39m\n\u001B[32m   1647\u001B[39m     \u001B[38;5;28;01myield\u001B[39;00m\n\u001B[32m   1649\u001B[39m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backend.retrieval_context():\n\u001B[32m-> \u001B[39m\u001B[32m1650\u001B[39m         \u001B[38;5;28;01myield from\u001B[39;00m \u001B[38;5;28mself\u001B[39m._retrieve()\n\u001B[32m   1652\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mGeneratorExit\u001B[39;00m:\n\u001B[32m   1653\u001B[39m     \u001B[38;5;66;03m# The generator has been garbage collected before being fully\u001B[39;00m\n\u001B[32m   1654\u001B[39m     \u001B[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001B[39;00m\n\u001B[32m   1655\u001B[39m     \u001B[38;5;66;03m# the user if necessary.\u001B[39;00m\n\u001B[32m   1656\u001B[39m     \u001B[38;5;28mself\u001B[39m._exception = \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniforge3/envs/works_3.12/lib/python3.12/site-packages/joblib/parallel.py:1762\u001B[39m, in \u001B[36mParallel._retrieve\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m   1757\u001B[39m \u001B[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001B[39;00m\n\u001B[32m   1758\u001B[39m \u001B[38;5;66;03m# async callbacks to progress.\u001B[39;00m\n\u001B[32m   1759\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m ((\u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m._jobs) == \u001B[32m0\u001B[39m) \u001B[38;5;129;01mor\u001B[39;00m\n\u001B[32m   1760\u001B[39m     (\u001B[38;5;28mself\u001B[39m._jobs[\u001B[32m0\u001B[39m].get_status(\n\u001B[32m   1761\u001B[39m         timeout=\u001B[38;5;28mself\u001B[39m.timeout) == TASK_PENDING)):\n\u001B[32m-> \u001B[39m\u001B[32m1762\u001B[39m     \u001B[43mtime\u001B[49m\u001B[43m.\u001B[49m\u001B[43msleep\u001B[49m\u001B[43m(\u001B[49m\u001B[32;43m0.01\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m   1763\u001B[39m     \u001B[38;5;28;01mcontinue\u001B[39;00m\n\u001B[32m   1765\u001B[39m \u001B[38;5;66;03m# We need to be careful: the job list can be filling up as\u001B[39;00m\n\u001B[32m   1766\u001B[39m \u001B[38;5;66;03m# we empty it and Python list are not thread-safe by\u001B[39;00m\n\u001B[32m   1767\u001B[39m \u001B[38;5;66;03m# default hence the use of the lock\u001B[39;00m\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 1.2 GradientBoosting",
   "id": "50f54c25a85cbc6b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-05T18:47:26.746810Z",
     "start_time": "2025-02-05T18:47:06.004979Z"
    }
   },
   "cell_type": "code",
   "source": "train_and_save_models(model_type='GradientBoosting', use_grid_search=True)",
   "id": "b81bc9807a11fa5a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting model training for GradientBoosting\n",
      "Model directory created: /Users/alexey-krasnov/Desktop/works/projects/ml_projects/BandGap-ml/band_gap_ml/models/gradientboosting\n",
      "1. Starting classification training...\n",
      "Importing GradientBoostingClassifier from sklearn.ensemble\n",
      "2. Training classification model with default parameters...\n",
      "GradientBoosting Classification Best Parameters: Default parameters\n",
      "Accuracy: 0.8902439024390244\n",
      "Precision: 0.872093023255814\n",
      "Recall: 0.9146341463414634\n",
      "F1 Score: 0.8928571428571429\n",
      "3. Training final classification model on entire dataset...\n",
      "Saving classification model to /Users/alexey-krasnov/Desktop/works/projects/ml_projects/BandGap-ml/band_gap_ml/models/gradientboosting/classification_gradientboosting.pkl\n",
      "Saving classification scaler to /Users/alexey-krasnov/Desktop/works/projects/ml_projects/BandGap-ml/band_gap_ml/models/gradientboosting/classification_gradientboosting_scaler.pkl\n",
      "\n",
      "4. Starting regression training\n",
      "Importing GradientBoostingRegressor from sklearn.ensemble\n",
      "5. Training regression model with default parameters...\n",
      "\n",
      "GradientBoosting Regression Best Parameters: Default parameters\n",
      "R2 Score: 0.8656056680547504\n",
      "MAE: 0.40897314816007807\n",
      "MSE: 0.3202955001872182\n",
      "RMSE: 0.5659465524121674\n",
      "Explained Variance Score: 0.8657218103277681\n",
      "6. Training final regression model on entire dataset\n",
      "Saving regression model to /Users/alexey-krasnov/Desktop/works/projects/ml_projects/BandGap-ml/band_gap_ml/models/gradientboosting/regression_gradientboosting.pkl\n",
      "Saving regression scaler to /Users/alexey-krasnov/Desktop/works/projects/ml_projects/BandGap-ml/band_gap_ml/models/gradientboosting/regression_gradientboosting_scaler.pkl\n",
      "Model training completed successfully\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 1.3 XGBoost",
   "id": "473df31113e924e6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T15:57:45.373506Z",
     "start_time": "2025-03-13T15:57:45.370961Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Customize model directory for saving models and scalers (optional)\n",
    "model_dir=''"
   ],
   "id": "855da0d156eeb41b",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T15:57:09.466800Z",
     "start_time": "2025-03-13T15:57:08.378661Z"
    }
   },
   "cell_type": "code",
   "source": "train_and_save_models(model_type='XGBoost', use_grid_search=False, model_dir=model_dir)",
   "id": "b768bb085f176b77",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting model training for XGBoost\n",
      "Model directory created: /Users/alekseikrasov/Desktop/OntoChem/work/ml_projects/test_dir/xgboost\n",
      "1. Start training of classifier ...\n",
      "Importing XGBClassifier from xgboost\n",
      "XGBoost Classification Best Parameters: Default parameters\n",
      "\n",
      "Accuracy: 0.9115853658536586\n",
      "Precision: 0.8994082840236687\n",
      "Recall: 0.926829268292683\n",
      "F1_score: 0.9129129129129129\n",
      "\n",
      "4. Start training regressor...\n",
      "Importing XGBRegressor from xgboost\n",
      "\n",
      "XGBoost Regression Best Parameters: Default parameters\n",
      "\n",
      "R2_SCORE: 0.9019038319218373\n",
      "MAE: 0.29294995465167056\n",
      "MSE: 0.23378784481658443\n",
      "RMSE: 0.4835161267388963\n",
      "EXPLAINED_VARIANCE_SCORE: 0.9019133875141188\n",
      "Saving classification model to /Users/alekseikrasov/Desktop/OntoChem/work/ml_projects/test_dir/xgboost/classification_model.pkl\n",
      "Saving classification scaler to /Users/alekseikrasov/Desktop/OntoChem/work/ml_projects/test_dir/xgboost/classification_scaler.pkl\n",
      "Saving regression model to /Users/alekseikrasov/Desktop/OntoChem/work/ml_projects/test_dir/xgboost/regression_model.pkl\n",
      "Saving regression scaler to /Users/alekseikrasov/Desktop/OntoChem/work/ml_projects/test_dir/xgboost/regression_scaler.pkl\n",
      "Model training completed successfully\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model_type': 'XGBoost',\n",
       " 'use_grid_search': False,\n",
       " 'classification': {'best_params': 'Default parameters',\n",
       "  'metrics': {'accuracy': 0.9115853658536586,\n",
       "   'precision': 0.8994082840236687,\n",
       "   'recall': 0.926829268292683,\n",
       "   'f1_score': 0.9129129129129129}},\n",
       " 'regression': {'best_params': 'Default parameters',\n",
       "  'metrics': {'r2_score': 0.9019038319218373,\n",
       "   'mae': 0.29294995465167056,\n",
       "   'mse': 0.23378784481658443,\n",
       "   'rmse': np.float64(0.4835161267388963),\n",
       "   'explained_variance_score': 0.9019133875141188}}}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "id": "372d5a86-80f1-47dd-9908-4ceb8957f105",
   "metadata": {},
   "source": "# 2. Prediction from csv file"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T15:57:17.874376Z",
     "start_time": "2025-03-13T15:57:17.871833Z"
    }
   },
   "cell_type": "code",
   "source": "input_file = '../samples/to_predict.csv'",
   "id": "2c6acb3f9830bb91",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2.1 RandomForest",
   "id": "33bc698bec0c635c"
  },
  {
   "cell_type": "code",
   "id": "97780f08-f0a3-4364-bcaa-f7ce70726742",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-04T20:49:38.085973Z",
     "start_time": "2025-02-04T20:49:38.008606Z"
    }
   },
   "source": [
    "predictions = predict_eg_from_file(input_file, model_type='RandomForest')\n",
    "predictions"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[np.float64(3.4190938888888933), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.int64(0), np.float64(3.5661508333333343), np.float64(3.157483333333332), np.float64(3.1493383333333327), np.float64(3.0604999999999984), np.float64(3.0374733333333337), np.int64(0), np.float64(3.4022892716398485)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexey-krasnov/miniforge3/envs/works_3.12/lib/python3.12/site-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/alexey-krasnov/miniforge3/envs/works_3.12/lib/python3.12/site-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[np.float64(3.4190938888888933),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.float64(3.5661508333333343),\n",
       " np.float64(3.157483333333332),\n",
       " np.float64(3.1493383333333327),\n",
       " np.float64(3.0604999999999984),\n",
       " np.float64(3.0374733333333337),\n",
       " np.int64(0),\n",
       " np.float64(3.4022892716398485)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2.2 GradientBoosting",
   "id": "2faf86226de980f2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T13:52:13.665302Z",
     "start_time": "2025-03-13T13:52:13.583493Z"
    }
   },
   "cell_type": "code",
   "source": [
    "predictions = predict_eg_from_file(input_file, model_type='GradientBoosting')\n",
    "predictions"
   ],
   "id": "2a98e4d70343be84",
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/alekseikrasov/Desktop/OntoChem/work/ml_projects/BandGap-ml/band_gap_ml/models/xgboost/classification_xgboost.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mFileNotFoundError\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[4]\u001B[39m\u001B[32m, line 3\u001B[39m\n\u001B[32m      1\u001B[39m input_file = \u001B[33m'\u001B[39m\u001B[33m../samples/to_predict.csv\u001B[39m\u001B[33m'\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m3\u001B[39m predictions = \u001B[43mpredict_eg_from_file\u001B[49m\u001B[43m(\u001B[49m\u001B[43minput_file\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel_type\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mXGBoost\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m      4\u001B[39m \u001B[38;5;28mprint\u001B[39m(predictions)\n\u001B[32m      5\u001B[39m predictions\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/OntoChem/work/ml_projects/BandGap-ml/band_gap_ml/band_gap_predictor.py:109\u001B[39m, in \u001B[36mpredict_eg_from_file\u001B[39m\u001B[34m(file_path, input_data, model_type)\u001B[39m\n\u001B[32m    105\u001B[39m     input_data.rename(columns={first_column: \u001B[33m'\u001B[39m\u001B[33mComposition\u001B[39m\u001B[33m'\u001B[39m}, inplace=\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[32m    107\u001B[39m X = prepare_features(input_data)\n\u001B[32m--> \u001B[39m\u001B[32m109\u001B[39m classifier_model, regressor_model, scaler_class, scaler_reg = \u001B[43mload_models_and_scalers\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_type\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    111\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m predict_band_gap(X, classifier_model, regressor_model, scaler_class, scaler_reg)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/OntoChem/work/ml_projects/BandGap-ml/band_gap_ml/band_gap_predictor.py:16\u001B[39m, in \u001B[36mload_models_and_scalers\u001B[39m\u001B[34m(model_type)\u001B[39m\n\u001B[32m     14\u001B[39m \u001B[38;5;250m\u001B[39m\u001B[33;03m\"\"\"Load models and scalers from pre-saved paths.\"\"\"\u001B[39;00m\n\u001B[32m     15\u001B[39m model_paths = Config.get_model_paths(model_type)\n\u001B[32m---> \u001B[39m\u001B[32m16\u001B[39m classifier_model = \u001B[43mload_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_paths\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mclassification_model\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     17\u001B[39m regressor_model = load_model(model_paths[\u001B[33m'\u001B[39m\u001B[33mregression_model\u001B[39m\u001B[33m'\u001B[39m])\n\u001B[32m     18\u001B[39m scaler_class = load_model(model_paths[\u001B[33m'\u001B[39m\u001B[33mclassification_scaler\u001B[39m\u001B[33m'\u001B[39m])\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/Desktop/OntoChem/work/ml_projects/BandGap-ml/band_gap_ml/band_gap_predictor.py:10\u001B[39m, in \u001B[36mload_model\u001B[39m\u001B[34m(filepath)\u001B[39m\n\u001B[32m      9\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mload_model\u001B[39m(filepath):\n\u001B[32m---> \u001B[39m\u001B[32m10\u001B[39m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mfilepath\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mrb\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mas\u001B[39;00m file:\n\u001B[32m     11\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m pickle.load(file)\n",
      "\u001B[31mFileNotFoundError\u001B[39m: [Errno 2] No such file or directory: '/Users/alekseikrasov/Desktop/OntoChem/work/ml_projects/BandGap-ml/band_gap_ml/models/xgboost/classification_xgboost.pkl'"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2.3 XGBoost",
   "id": "15b1c1eb4bad2da2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T15:57:54.609519Z",
     "start_time": "2025-03-13T15:57:54.582723Z"
    }
   },
   "cell_type": "code",
   "source": [
    "predictions = predict_eg_from_file(input_file, model_type='XGBoost', model_dir=model_dir)\n",
    "predictions"
   ],
   "id": "a19e2cfcd5fcc9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading models and scalers for XGBoost from {'classification_model': PosixPath('/Users/alekseikrasov/Desktop/OntoChem/work/ml_projects/test_dir/xgboost/classification_model.pkl'), 'regression_model': PosixPath('/Users/alekseikrasov/Desktop/OntoChem/work/ml_projects/test_dir/xgboost/regression_model.pkl'), 'classification_scaler': PosixPath('/Users/alekseikrasov/Desktop/OntoChem/work/ml_projects/test_dir/xgboost/classification_scaler.pkl'), 'regression_scaler': PosixPath('/Users/alekseikrasov/Desktop/OntoChem/work/ml_projects/test_dir/xgboost/regression_scaler.pkl')}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alekseikrasov/miniforge3/envs/works_3.12/lib/python3.12/site-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/alekseikrasov/miniforge3/envs/works_3.12/lib/python3.12/site-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[np.float32(3.3633704),\n",
       " np.float32(3.5537503),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.float32(3.5693252),\n",
       " np.int64(0),\n",
       " np.int64(0),\n",
       " np.float32(3.5278072),\n",
       " np.float32(3.1601152),\n",
       " np.float32(2.7337983),\n",
       " np.float32(3.089959),\n",
       " np.float32(2.4396708),\n",
       " np.int64(0),\n",
       " np.float32(3.4009721)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "id": "5e73c134-5b5e-410f-ae83-5822c19678db",
   "metadata": {},
   "source": "# 3. Prediction from one or multiple chemical formula"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T15:58:01.920913Z",
     "start_time": "2025-03-13T15:58:01.918319Z"
    }
   },
   "cell_type": "code",
   "source": [
    "formula_1 = 'BaLa2In2O7'\n",
    "formula_2 = 'TiO2'\n",
    "formula_3 = 'Bi4Ti3O12'\n",
    "formula_4 = 'Bi2Ti2O7'\n",
    "formula_5 = 'BaTaO2N'\n",
    "formulas = [formula_1, formula_2, formula_3, formula_4]"
   ],
   "id": "29a17fcde1f83c13",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 3.1 RandomForest",
   "id": "30b22aecd72cfed0"
  },
  {
   "cell_type": "code",
   "id": "8410f5ee-9fc1-42dd-bc25-a3576444ad69",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-05T18:54:11.054522Z",
     "start_time": "2025-02-05T18:54:11.012043Z"
    }
   },
   "source": [
    "predictions = predict_eg_from_formula(formula=formulas, model_type='RandomForest')\n",
    "for formula, prediction in zip(formulas, predictions):\n",
    "    print(f'Prediction for {formula}: {prediction:.2f} eV')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[np.float64(3.0808866666666654), np.float64(3.425520000000002), np.float64(3.0835486363636364), np.float64(3.133338636363636)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexey-krasnov/miniforge3/envs/works_3.12/lib/python3.12/site-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/alexey-krasnov/miniforge3/envs/works_3.12/lib/python3.12/site-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 3.2 GradientBoosting",
   "id": "894aea6ed405037"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T13:34:05.814969Z",
     "start_time": "2025-03-13T13:34:05.793928Z"
    }
   },
   "cell_type": "code",
   "source": [
    "predictions = predict_eg_from_formula(formula=formulas, model_type='GradientBoosting')\n",
    "for formula, prediction in zip(formulas, predictions):\n",
    "    print(f'Prediction for {formula}: {prediction:.2f} eV')"
   ],
   "id": "efe028d32260eedd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[np.int64(0), np.float32(3.3633704), np.float32(2.4396708), np.float32(2.7337983)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alekseikrasov/miniforge3/envs/works_3.12/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [14:34:05] WARNING: /Users/runner/work/xgboost/xgboost/src/gbm/../common/error_msg.h:80: If you are loading a serialized model (like pickle in Python, RDS in R) or\n",
      "configuration generated by an older version of XGBoost, please export the model by calling\n",
      "`Booster.save_model` from that version first, then load it back in current version. See:\n",
      "\n",
      "    https://xgboost.readthedocs.io/en/stable/tutorials/saving_model.html\n",
      "\n",
      "for more details about differences between saving model and serializing.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/alekseikrasov/miniforge3/envs/works_3.12/lib/python3.12/site-packages/sklearn/base.py:380: InconsistentVersionWarning: Trying to unpickle estimator StandardScaler from version 1.6.0 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "/Users/alekseikrasov/miniforge3/envs/works_3.12/lib/python3.12/site-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/alekseikrasov/miniforge3/envs/works_3.12/lib/python3.12/site-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 3.3 XGBoost",
   "id": "e804eda2868ba68b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-13T15:58:09.334515Z",
     "start_time": "2025-03-13T15:58:09.319181Z"
    }
   },
   "cell_type": "code",
   "source": [
    "predictions = predict_eg_from_formula(formula=formulas, model_type='XGBoost', model_dir=model_dir)\n",
    "for formula, prediction in zip(formulas, predictions):\n",
    "    print(f'Prediction for {formula}: {prediction:.2f} eV')"
   ],
   "id": "6831081eb2839de3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading models and scalers for XGBoost from {'classification_model': PosixPath('/Users/alekseikrasov/Desktop/OntoChem/work/ml_projects/test_dir/xgboost/classification_model.pkl'), 'regression_model': PosixPath('/Users/alekseikrasov/Desktop/OntoChem/work/ml_projects/test_dir/xgboost/regression_model.pkl'), 'classification_scaler': PosixPath('/Users/alekseikrasov/Desktop/OntoChem/work/ml_projects/test_dir/xgboost/classification_scaler.pkl'), 'regression_scaler': PosixPath('/Users/alekseikrasov/Desktop/OntoChem/work/ml_projects/test_dir/xgboost/regression_scaler.pkl')}\n",
      "Prediction for BaLa2In2O7: 0.00 eV\n",
      "Prediction for TiO2: 3.36 eV\n",
      "Prediction for Bi4Ti3O12: 2.44 eV\n",
      "Prediction for Bi2Ti2O7: 2.73 eV\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alekseikrasov/miniforge3/envs/works_3.12/lib/python3.12/site-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n",
      "/Users/alekseikrasov/miniforge3/envs/works_3.12/lib/python3.12/site-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "55f1a628ed59b23c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
